from pathlib import Path
import streamlit as st
from Menu import menu
import pickle
import plotly.graph_objs as go
import streamlit_shadcn_ui as ui

st.set_page_config(page_title='Wykresy procesu uczenia', page_icon='', layout='wide')

menu()

st.title('Wykresy procesu uczenia')
st.markdown('Zobacz jak przebiega proces uczenia si modelu analizujc wykresy dokadnoci oraz funkcji straty.')

with open(str(Path(__file__).parents[1]) + '/Model/model_history.pickle', 'rb') as file:
    history = pickle.load(file, encoding='latin1')

cols = st.columns(2, gap='large')

with cols[0]:
    fig = go.Figure()
    fig.add_trace(go.Line(x=list(range(1,len(history['train_accuracy_history'])+1)),
                             y=history['train_accuracy_history'],
                             name='Zbi贸r treningowy',
                             line=dict(color='blue'),
                          mode='lines+markers'))
    fig.add_trace(go.Line(x=list(range(1,len(history['validation_accuracy_history'])+1)),
                             y=history['validation_accuracy_history'],
                             name='Zbi贸r walidacyjny',
                             line=dict(color='orange'),
                            mode='lines+markers'))
    fig.update_layout(
        xaxis=dict(showline=True, showgrid=True),
        yaxis=dict(dtick=0.1),
        title='Dokadno na zbiorze treningowym i walidacyjnym w zale偶noci od epoki',
        xaxis_title='Numer epoki',
        yaxis_title='Dokadno',
        width=700,
        height=600
    )
    st.plotly_chart(fig)
    #fig.write_image(str(Path(__file__).parents[1]) + '/pages/Learning_process_history/Accuracy_history.jpg')

    ui.metric_card(title='Najwiksza dokadno', content=str(round(100*max(history['validation_accuracy_history']), 2)) + '%',
                   description='Dokadno informuje o tym, jaka cz wszystkich predykcji modelu jest poprawna.')


with cols[1]:
    fig = go.Figure()
    fig.add_trace(go.Line(x=list(range(1,len(history['train_loss_history'])+1)),
                             y=history['train_loss_history'],
                             name='Zbi贸r treningowy',
                             line=dict(color='blue'),
                            mode='lines+markers'))
    fig.add_trace(go.Line(x=list(range(1,len(history['validation_loss_history'])+1)),
                             y=history['validation_loss_history'],
                             name='Zbi贸r walidacyjny',
                             line=dict(color='orange'),
                            mode='lines+markers'))
    fig.update_layout(
        xaxis=dict(showline=True, showgrid=True),
        yaxis=dict(dtick=0.25),
        title='Funkcja straty na zbiorze treningowym i walidacyjnym w zale偶noci od epoki',
        xaxis_title='Numer epoki',
        yaxis_title='Warto funkcji straty',
        width=700,
        height=600
    )
    st.plotly_chart(fig)
    
    #fig.write_image(str(Path(__file__).parents[1]) + 'pages/Learning_process_history/Loss_history.jpg')

    ui.metric_card(title='Najmniejsza strata', content=round(min(history['validation_loss_history']), 2), description='Funkcja straty su偶y do oceny bdu, kt贸ry model popenia na zbiorze.')


with st.expander("Wnioski", expanded=True):
        st.write("Patrzc na powy偶sze wykresy mo偶na zauwa偶y, 偶e mamy do czynienia ze zjawiskiem przeuczenia modelu. "
                 "Sie zbyt mocno dopasowaa si do danych treningowych nie poprawiajc tym samym, w kolejnych epokach, dokadnoci predykcji na zbiorze walidacyjnym. ")

        st.write("Dokonujc og贸lnej oceny modelu warto jednak zdawa sobie spraw z ogranicze zwizanych z jego implementacj oraz samym zbiorem danych. CIFAR-5 prezentujc rodki transportu, bdce zo偶onymi obiektami, "
                 "wykorzystuje do tego celu obrazy o niskiej rozdzielczoci. Przekada si to na zmniejszenie szczeg贸owoci obiekt贸w, ograniczajc tym samym ilo dostpnych dla sieci informacji.  "
                 "Modele wykorzystujce obrazy maych rozmiar贸w maj tendencj do zapamitywania szczeg贸贸w danych treningowych, zamiast nauki bardziej og贸lnych wzorc贸w. "
                 "Stosowanie w tym przypadku du偶ej liczby warstw konwolucyjnch mo偶e doprowadzi do zredukowania mapy cech do zbyt maego rozmiaru, co uniemo偶liwi skuteczne uczenie si bardziej zo偶onych wzorc贸w. ")

        st.write("W kontekcie doboru architektury sieci kluczowe byo zachowanie kompromisu midzy czasem trenowania, a jakoci uzyskiwanych wynik贸w. "
                 "Skorzystanie z wasnej implementacji konwolucyjnej sieci neuronowej, zbudowanej bez szczeg贸lnego nacisku na optymalizacj, wymagao przemylanego balansu midzy zo偶onoci modelu, a jego efektywnoci obliczeniow.")
